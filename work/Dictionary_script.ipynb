{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create dictionary full of adjectives and insert them into the key-value db redis\n",
    "\n",
    "## Parse dictionary files (json and custom file format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7503003-f942-447a-bc0f-11cdff054e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['celtic', 'ambulacral', 'austere', 'breakaway', 'leafed', 'lobed', 'maternalistic', 'predaceous', 'stillborn', 'young']\n",
      "Waiting for new events...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New event received\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Natural Language Toolkit already offers many libraries regarding computer linguistics\n",
    "# E.g. \"from nltk.corpus import wordnet as wn\" could be used to categorise the part of speech of a given word\n",
    "# For education's sake, we try to create our own list of adjectives using Wordnet and/or a json file\n",
    "\n",
    "# allowed_specials (syntactic markers)\n",
    "# p predicate position\n",
    "# a prenominal (attributive) position\n",
    "# ip immediately postnominal position\n",
    "def read_word_net_dictionary(file_path, allowed_specials = [], allow_adjective_satellite = True):\n",
    "    adjectives_word_net = set()\n",
    "\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        #https://wordnet.princeton.edu/documentation/wndb5wn\n",
    "        #https://wordnet.princeton.edu/documentation/wninput5wn\n",
    "                                             # word with opt. info (.) followed by space + hexCode + space\n",
    "        match = re.search(r\"\\d+ \\w{2} (\\w) \\w{2} ((?:[a-zA-Z_\\-.']+(?:\\((a|p|ip)\\))? [0-9a-fA-F] )+)\", line)\n",
    "        if match is not None:\n",
    "            # between words is a one-digit hex code distinctly identifying a word within a lexicographer's file\n",
    "            words = re.sub(r\" [0-9a-fA-F] \", \" \", match.group(2)).strip()\n",
    "            # replace multiple spaces with single space\n",
    "            words = re.sub(r\" +\", \" \", words).split(\" \")\n",
    "            for word in words:\n",
    "                # _ in word means space -> two words | remove all words which are adjectives only in a certain context | potentially remove adjective satellite\n",
    "                syntactic_marker_match = re.search(r'\\((.{1,2})\\)$', word)\n",
    "                # if no markers exist or this marker is whitelisted\n",
    "                is_marker_allowed = syntactic_marker_match is None or syntactic_marker_match.group(1) in allowed_specials\n",
    "                # if adjective satellites are allowed, or it isn't an adjective satellite\n",
    "                show_adjective_satellites = allow_adjective_satellite or match.group(1) != 's'\n",
    "                if \"_\" not in word and show_adjective_satellites and is_marker_allowed:\n",
    "                    word = re.sub(r\"\\(.+\\)\", \"\", word)\n",
    "                    adjectives_word_net.add(word.lower())\n",
    "    return adjectives_word_net\n",
    "\n",
    "def read_nltk_extraction(directory_path):\n",
    "    adjectives_nltk = set()\n",
    "\n",
    "    # traverse directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        # if path leads to file\n",
    "        if os.path.isfile(file_path):\n",
    "            # open file and read as json\n",
    "            with open(file_path, \"r\") as file:\n",
    "                file_json = json.load(file)\n",
    "            # loop through json dictionary entries\n",
    "            for key, value in file_json.items():\n",
    "                # if meanings is empty\n",
    "                if value['MEANINGS'] is None or not value['MEANINGS']:\n",
    "                    continue\n",
    "                for key_meaning, value_meaning in value['MEANINGS'].items():\n",
    "                    # only take first meaning into consideration - if not enough adjectives are found, evaluate better approach\n",
    "                    # e.g. by taking words whose adjective-meanings make up >= 50% of all meanings\n",
    "                    if value_meaning[0].lower() == 'adjective':\n",
    "                        adjectives_nltk.add(key.lower())\n",
    "                    break\n",
    "    return adjectives_nltk\n",
    "\n",
    "import redis\n",
    "\n",
    "# create connection to redis db\n",
    "redis_conn = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)\n",
    "# remove existing entries\n",
    "redis_conn.flushdb()\n",
    "\n",
    "# all adjectives + markers\n",
    "#adjectives = read_word_net_dictionary(\"./adjectives_wordnet.adj\", ['a', 'ip', 'p'], True)\n",
    "\n",
    "# without adjective satellites\n",
    "#adjectives = read_word_net_dictionary(\"./adjectives_wordnet.adj\", [], False)\n",
    "\n",
    "# using dictionary json\n",
    "adjectives  = read_nltk_extraction('./Dictionary JSON')\n",
    "\n",
    "# preview\n",
    "print(list(adjectives)[0:10])\n",
    "\n",
    "for adjective in adjectives:\n",
    "    # insert adjective into redis db (value is irrelevant)\n",
    "    redis_conn.set(adjective, 1)\n",
    "\n",
    "# test - value is string if not None (weird, but okay)\n",
    "assert redis_conn.get(\"excited\") == '1'\n",
    "assert redis_conn.get(\"house\") is None\n",
    "\n",
    "from Kafka_Helpers import Producer, Consumer\n",
    "\n",
    "# fill blacklist if necessary\n",
    "blacklist = { }\n",
    "\n",
    "dictionary_producer = Producer('localhost', 29092)\n",
    "\n",
    "def subscribe_handler(key, value):\n",
    "    infos_and_reviews = json.loads(value)\n",
    "    reviews = infos_and_reviews['reviews']\n",
    "    reviews_words = [[word for word in review if word not in blacklist and redis_conn.get(word) is not None] for review in reviews]\n",
    "    dictionary_producer.send('adjectives', key, {\n",
    "        'movie_id': infos_and_reviews['movie_id'],\n",
    "        'title': infos_and_reviews['title'],\n",
    "        'reviews': reviews_words\n",
    "    })\n",
    "\n",
    "dictionary_consumer = Consumer('localhost', 29092, 'movie_reviews', subscribe_handler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Get adjectives and fill RedisDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec802dfe-be0f-4bcb-9fe0-d52245fe6372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import redis\n",
    "\n",
    "# create connection to redis db\n",
    "redis_conn = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)\n",
    "# remove existing entries\n",
    "# redis_conn.flushdb()\n",
    "\n",
    "# all adjectives + markers\n",
    "#adjectives = read_word_net_dictionary(\"./adjectives_wordnet.adj\", ['a', 'ip', 'p'], True)\n",
    "\n",
    "# without adjective satellites\n",
    "#adjectives = read_word_net_dictionary(\"./adjectives_wordnet.adj\", [], False)\n",
    "\n",
    "# using dictionary json\n",
    "adjectives  = read_nltk_extraction('./Dictionary JSON')\n",
    "\n",
    "# preview\n",
    "print(list(adjectives)[0:10])\n",
    "\n",
    "# for adjective in adjectives:\n",
    "#     # insert adjective into redis db (value is irrelevant)\n",
    "#     redis_conn.set(adjective, 1)\n",
    "\n",
    "# test - value is string if not None (weird, but okay)\n",
    "assert redis_conn.get(\"excited\") == '1'\n",
    "assert redis_conn.get(\"house\") is None\n",
    "\n",
    "print(redis_conn.get(\"the\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Subscribe to the 'movie reviews' topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad81ebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Kafka_Helpers import Producer, Consumer\n",
    "\n",
    "# fill blacklist if necessary\n",
    "blacklist = { }\n",
    "\n",
    "dictionary_producer = Producer('localhost', 29092)\n",
    "\n",
    "def subscribe_handler(key, value):\n",
    "    infos_and_reviews = json.loads(value)\n",
    "    reviews = infos_and_reviews['reviews']\n",
    "    reviews_words = [[word for word in review if word not in blacklist and redis_conn.get(word) is not None] for review in reviews]\n",
    "    dictionary_producer.send('adjectives', key, {\n",
    "        'movie_id': infos_and_reviews['movie_id'],\n",
    "        'tile': infos_and_reviews['title'],\n",
    "        'reviews': reviews_words\n",
    "    })\n",
    "\n",
    "dictionary_consumer = Consumer('localhost', 29092, 'movie_reviews', subscribe_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Simulate receiving movie infos and reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f2b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# from secrets import api_key\n",
    "import json\n",
    "\n",
    "api_key = \"105864a59e519ef281a74ca3af6c1b17\"\n",
    "\n",
    "test_producer = Producer('localhost', 29092)\n",
    "\n",
    "request = requests.get(\"https://api.themoviedb.org/3/movie/now_playing?language=en-US\", {'api_key': api_key})\n",
    "response = request.json()\n",
    "first_result = response['results'][0]\n",
    "\n",
    "request = requests.get(f\"https://api.themoviedb.org/3/movie/{first_result['id']}/reviews?language=en-US\", {'api_key': api_key})\n",
    "response = request.json()\n",
    "\n",
    "reviews = [review['content'] for review in response['results']]# for word in re.sub(r\"[^\\w\\-']\", \" \", result['content']).split(\" \")]\n",
    "result = [re.sub(r\"[^\\w \\-]\", \"\", review.lower()).split(\" \") for review in reviews]\n",
    "\n",
    "test_producer.send(\"movie_reviews\", \"key\", json.dumps({\n",
    "    \"movie_id\": first_result['id'],\n",
    "    \"title\": first_result['title'],\n",
    "    \"reviews\": result\n",
    "}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
